import urllib.request
import requests
from bs4 import BeautifulSoup
import argparse
import urllib
import os
import time

# ãƒ­ã‚°ã‚¤ãƒ³ç”¨ã®URLï¼ˆãƒ­ã‚°ã‚¤ãƒ³ç”»é¢ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ï¼‰
login_url = 'https://panda.ecs.kyoto-u.ac.jp/cas/login?service=https%3A%2F%2Fpanda.ecs.kyoto-u.ac.jp%2Fsakai-login-tool%2Fcontainer'
base_url = 'https://panda.ecs.kyoto-u.ac.jp/direct'
# test: é…å¸ƒè³‡æ–™ã‚’ç¤ºã™ID
id = 'ae7eb08f-5eab-41d2-a8d8-229aac826b97'

# ãƒ­ã‚°ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã‹ã‚‰login tokenã‚’å–å¾—
def get_lt_value():
    # ãƒ­ã‚°ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã‚’å–å¾—
    res_page = session.get(login_url)
    soup = BeautifulSoup(res_page.text, 'html.parser')
    lt_value = soup.find('input', {'name': 'lt'})['value']
    return lt_value

# ãƒ­ã‚°ã‚¤ãƒ³
def login(username, password, lt):
    login_data = {
        'username': username,
        'password': password,
        'lt': lt,
        'execution': 'e1s1',
        '_eventId': 'submit',
        'submit': 'ãƒ­ã‚°ã‚¤ãƒ³',
    }
    print(f'Logging in as: {username}...')
    return session.post(login_url, data=login_data)

def site():
    params_site = {
        '_limit': 50,
    }
    res_site = session.get(base_url + '/site' + '.json', params=params_site)
    for site in res_site.json()['site_collection']:
        print(f"{site['title']} ({site['id']})")

    return res_site


def ls(resource_id):
    res_content = session.get(base_url + '/content' + '/resources' + '/' + resource_id + '.json')
    # ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®é …ç›®
    for site in res_content.json()['content_collection']:
        if (site['type'] == 'org.sakaiproject.content.types.folder'):
            print('ğŸ“', end='')
        else:
            print('ğŸ“„', end='')
        print(f"{site['name']}")

def download(site_id):
    # ã‚µã‚¤ãƒˆã®ã™ã¹ã¦ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª/ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
    print('Fetching Files...')
    res_site = session.get(base_url + '/content' + '/site' + '/' + site_id + '.json')
    print('Downloading...')
    for content in res_site.json()['content_collection']:
        if (content['type'] != 'collection'):
            # data = urllib.request.urlopen(content['url']).read()
            os.makedirs('save' + content['container'], exist_ok=True)
            try:
                with open('save' + content['container'] + content['title'], mode='xb') as f:
                    res_file = session.get(content['url'])
                    f.write(res_file.content)
                    print(f'Download: {content['title']}')
            except FileExistsError:
                # print(f'Pass: {content['title']}')
                pass
    print('Done!')



# # ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®é …ç›®
# for site in res_content.json()['content_collection']:
#     # print(f"|--{site['name']}")
#     for child in site['resourceChildren']:
#         # å„childãŒé …ç›®ã‚’æŒã¤ãªã‚‰ï¼Œãã‚Œã‚’å–å¾—
#         if (child['type'] == 'org.sakaiproject.content.types.folder'):
#             resource_id = child['resourceId']
#             res_content_child = session.get(base_url + '/content' + '/resources' + resource_id + '.json')
#             with open('a.json', 'w') as f:
#                 f.write(res_content_child.text)
#             for site_child in res_content_child.json()['content_collection']:
#                 if (site_child['type'] == 'org.sakaiproject.content.types.folder'):
#                     for site_grand_child in site_child['resourceChildren']:
#                         print("  ", end='')
#                         print(f"|--{site_grand_child['name']}")
#                     else:
#                         print(f"|--{site_child['name']}")
#                 else:
#                     print(f"|--{site_child['name']}")
#         else:
#             print(f"|--{site['name']}")



# # ã‚µã‚¤ãƒˆã®ã™ã¹ã¦ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª/ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
# res_site = session.get(base_url + '/content' + '/site' + '/' + id + '.json')
# for content in res_site.json()['content_collection']:
#     print(content['container'])

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹
session = requests.Session()

# print(get_lt_value())

# ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’å—ã‘ä»˜ã‘ã‚‹
parser = argparse.ArgumentParser(
    prog='PandA CLI'
)
parser.add_argument('ID')
parser.add_argument('password')
args = parser.parse_args()

res_login = login(args.ID, args.password, get_lt_value())

# ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’å–å¾—ã—ã¦ã¿ã‚‹
res_session = session.get(base_url + '/session' + '.json')

# ãƒ­ã‚°ã‚¤ãƒ³çŠ¶æ…‹ã‚’ç¢ºèª
print(f"logged in as: {res_session.json()['session_collection'][0]['userEid']}")
# ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
# ls(id)
# res_site = site()

# download('2024-110-6115-000')

# ç ”ç©¶å®¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
download(id)
